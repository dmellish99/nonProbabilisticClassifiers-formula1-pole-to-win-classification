{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3913e5ef-f7fb-46c7-816f-ecbfbc709e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07efca16-66cf-4642-b009-21d95c002924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27e4c3e0-fbd6-44fd-962d-bfd4b2603c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleaned.csv')\n",
    "\n",
    "## remove rows containing null values\n",
    "\n",
    "df=df.replace(np.nan,None)\n",
    "df=df[~df.isnull().all(1)]\n",
    "\n",
    "\n",
    "x=df.iloc[:,:-1]\n",
    "\n",
    "x_cols=x.columns\n",
    "\n",
    "## for x select all columns except the last\n",
    "X=df.iloc[:,:-1].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "## for y select the last\n",
    "\n",
    "y=df.iloc[:,-1].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22cb129c-dfb6-4eb8-8c9e-6a3f42bb8d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finished_first_q1</th>\n",
       "      <th>finished_first_q2</th>\n",
       "      <th>dif_seconds_quali_first_second</th>\n",
       "      <th>dif_seconds_quali_second_third</th>\n",
       "      <th>dif_seconds_quali_third_fourth</th>\n",
       "      <th>dif_seconds_qualif_fourth_fifth</th>\n",
       "      <th>isAmericas</th>\n",
       "      <th>isAustralia</th>\n",
       "      <th>isEurope</th>\n",
       "      <th>is_reigning_constructor_champion</th>\n",
       "      <th>is_reigning_driver_champion</th>\n",
       "      <th>driverAge</th>\n",
       "      <th>hadRain</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_humidity</th>\n",
       "      <th>avg_pressure</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>finishedFirst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8290</td>\n",
       "      <td>0</td>\n",
       "      <td>87.916667</td>\n",
       "      <td>35.291667</td>\n",
       "      <td>1012.550000</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8304</td>\n",
       "      <td>0</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>49.168333</td>\n",
       "      <td>1009.616667</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.346</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12273</td>\n",
       "      <td>0</td>\n",
       "      <td>88.100000</td>\n",
       "      <td>67.860000</td>\n",
       "      <td>1007.600000</td>\n",
       "      <td>8.783333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8325</td>\n",
       "      <td>0</td>\n",
       "      <td>67.350000</td>\n",
       "      <td>73.275000</td>\n",
       "      <td>1016.266667</td>\n",
       "      <td>15.633333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12308</td>\n",
       "      <td>0</td>\n",
       "      <td>66.350000</td>\n",
       "      <td>61.245000</td>\n",
       "      <td>1006.733333</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   finished_first_q1  finished_first_q2  dif_seconds_quali_first_second  \\\n",
       "0                  0                  1                           0.141   \n",
       "1                  1                  1                           0.116   \n",
       "2                  0                  0                           1.346   \n",
       "3                  0                  0                           0.250   \n",
       "4                  1                  1                           0.106   \n",
       "\n",
       "   dif_seconds_quali_second_third  dif_seconds_quali_third_fourth  \\\n",
       "0                           0.366                           0.609   \n",
       "1                           0.076                           0.564   \n",
       "2                           0.116                           0.125   \n",
       "3                           0.105                           0.010   \n",
       "4                           0.728                           0.108   \n",
       "\n",
       "   dif_seconds_qualif_fourth_fifth  isAmericas  isAustralia  isEurope  \\\n",
       "0                            0.024           0            0         0   \n",
       "1                            0.162           0            0         0   \n",
       "2                            0.087           0            0         0   \n",
       "3                            0.056           0            0         0   \n",
       "4                            0.054           0            0         0   \n",
       "\n",
       "   is_reigning_constructor_champion  is_reigning_driver_champion  driverAge  \\\n",
       "0                               0.0                          0.0       8290   \n",
       "1                               0.0                          0.0       8304   \n",
       "2                               0.0                          0.0      12273   \n",
       "3                               0.0                          0.0       8325   \n",
       "4                               0.0                          0.0      12308   \n",
       "\n",
       "   hadRain   avg_temp  avg_humidity  avg_pressure  avg_wind_speed  \\\n",
       "0        0  87.916667     35.291667   1012.550000        7.833333   \n",
       "1        0  75.400000     49.168333   1009.616667       13.166667   \n",
       "2        0  88.100000     67.860000   1007.600000        8.783333   \n",
       "3        0  67.350000     73.275000   1016.266667       15.633333   \n",
       "4        0  66.350000     61.245000   1006.733333        8.600000   \n",
       "\n",
       "   finishedFirst  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7fddb1a-687d-4cf4-816a-0479eef861b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finishedFirst\n",
       "1    151\n",
       "0    142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check dataset to see if it's imabalanced\n",
    "\n",
    "df['finishedFirst'].value_counts()\n",
    "\n",
    "## Dataset is nearly balanced \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a096791-09b9-4801-ac40-7a39b924e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## due to differences in data scale we will apply standard scaling.\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "\n",
    "X_scaled=scaler.transform(X)\n",
    "\n",
    "data_out=pd.DataFrame(X_scaled,columns=x_cols)\n",
    "\n",
    "data_out['finishedFirst']=y\n",
    "\n",
    "def toStr(val):\n",
    "    if val==1:\n",
    "        return 'y'\n",
    "    if val==0:\n",
    "        return 'n'\n",
    "\n",
    "data_out['finishedFirst']=data_out['finishedFirst'].apply(lambda x: toStr(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_out.to_csv('dataset_scaled.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9181e1be-620c-4533-aec4-7eb5def82437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameter K: {'n_neighbors': 8}\n",
      "0.6449887387387387\n",
      "[0.81081081 0.54054054 0.59459459 0.59459459 0.7027027  0.52777778\n",
      " 0.58333333 0.77777778]\n",
      "[[15 10]\n",
      " [12 22]]\n",
      "Precision:0.6/n\n",
      "Recall:0.5555555555555556/n\n",
      "F1:0.5769230769230769/n\n"
     ]
    }
   ],
   "source": [
    "### K-Nearest Neighbors \n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "\n",
    "## use gridsearch \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid ={\"n_neighbors\":np.arange(1,25)}\n",
    "knn= KNeighborsClassifier()\n",
    "knn_cv=GridSearchCV(knn,grid,cv=10) #GridSearchCV\n",
    "knn_cv.fit(X_train,y_train)\n",
    "print(\"tuned hyperparameter K:\",knn_cv.best_params_)\n",
    "\n",
    "## gridsearch output returns 13, so we use 13 \n",
    "\n",
    "\n",
    "\n",
    "## use KFold CV as well \n",
    "from sklearn.model_selection import KFold\n",
    "scores=[]\n",
    "kFold=KFold(n_splits=8,shuffle=False)\n",
    "\n",
    "## use best gridsearch parameter\n",
    "knn=KNeighborsClassifier(n_neighbors=13)\n",
    "for train_index,test_index in kFold.split(X_scaled):\n",
    "    # print(\"Train Index: \", train_index, \"\\n\")\n",
    "    # print(\"Test Index: \", test_index)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X_scaled[train_index], X_scaled[test_index], y[train_index], y[test_index]\n",
    "   \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n",
    "\n",
    "## finally, run the algorithm one last time on a random split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "scores.append(knn.score(X_test,y_test))\n",
    "\n",
    "print(cross_val_score(knn, X_scaled, y, cv=8))\n",
    "\n",
    "preds=knn.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "    \n",
    "C=confusion_matrix(y_test, preds)\n",
    "\n",
    "print(C)\n",
    "\n",
    "\n",
    "tp=C[0,0]\n",
    "tn=C[1,1]\n",
    "\n",
    "fp=C[0,1]\n",
    "fn=C[1,0]\n",
    "\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "\n",
    "\n",
    "\n",
    "f1=2*tp/((2*tp)+fp+fn)\n",
    "\n",
    "print('Precision:'+str(precision)+'/n')\n",
    "print('Recall:'+str(recall)+'/n')\n",
    "print('F1:'+str(f1)+'/n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2857c6a-551e-44e8-bfe9-c964d91e2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['C:\\\\Users\\\\melli\\\\anaconda3\\\\Lib\\\\site-packages\\\\weka\\\\lib\\\\arpack_combined.jar', 'C:\\\\Users\\\\melli\\\\anaconda3\\\\Lib\\\\site-packages\\\\weka\\\\lib\\\\core.jar', 'C:\\\\Users\\\\melli\\\\anaconda3\\\\Lib\\\\site-packages\\\\weka\\\\lib\\\\mtj.jar', 'C:\\\\Users\\\\melli\\\\anaconda3\\\\Lib\\\\site-packages\\\\weka\\\\lib\\\\python-weka-wrapper.jar', 'C:\\\\Users\\\\melli\\\\anaconda3\\\\Lib\\\\site-packages\\\\weka\\\\lib\\\\weka.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "JVM cannot be restarted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(jvm\u001b[38;5;241m.\u001b[39mstarted)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jvm\u001b[38;5;241m.\u001b[39mstarted:\n\u001b[1;32m---> 11\u001b[0m     jvm\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweka\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifiers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Classifier\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweka\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Loader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\weka\\core\\jvm.py:166\u001b[0m, in \u001b[0;36mstart\u001b[1;34m(class_path, bundled, packages, system_cp, max_heap_size, system_info, auto_install, logging_level)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# headless mode\u001b[39;00m\n\u001b[0;32m    164\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-Djava.awt.headless=true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 166\u001b[0m jpype\u001b[38;5;241m.\u001b[39mstartJVM(\u001b[38;5;241m*\u001b[39margs, classpath\u001b[38;5;241m=\u001b[39mfull_cp, convertStrings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    167\u001b[0m started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weka_home \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\jpype\\_core.py:207\u001b[0m, in \u001b[0;36mstartJVM\u001b[1;34m(jvmpath, classpath, ignoreUnrecognized, convertStrings, interrupt, *jvmargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _JVM_started\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _JVM_started:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJVM cannot be restarted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# JVM path\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jvmargs:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# jvm is the first argument the first argument is a path or None\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: JVM cannot be restarted"
     ]
    }
   ],
   "source": [
    "### Rule Induction\n",
    "\n",
    "import weka.core.jvm as jvm\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] ='C:/Users/melli/Downloads/openrefine-win-with-java-3.8.2/openrefine-3.8.2/server/target/jre/bin/client'\n",
    "\n",
    "print(jvm.started)\n",
    "\n",
    "if not jvm.started:\n",
    "    jvm.start()\n",
    "\n",
    "from weka.classifiers import Classifier\n",
    "from weka.core.converters import Loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset (ARFF or CSV format)\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")  # Use CSVLoader if CSV\n",
    "data = loader.load_file(\"dataset_scaled.arff\")\n",
    "data.class_is_last()  # Specify the class attribute\n",
    "\n",
    "# Build the PART classifier\n",
    "part = Classifier(classname=\"weka.classifiers.rules.PART\")\n",
    "part.build_classifier(data)\n",
    "\n",
    "jvm.stop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4dd2925-3fcb-4b3f-890d-256c38dd0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 17)\n",
      "0.648367117117117\n",
      "[0.81081081 0.62162162 0.64864865 0.56756757 0.59459459 0.58333333\n",
      " 0.58333333 0.75      ]\n",
      "[[18 11]\n",
      " [ 9 21]]\n",
      "Precision:0.6206896551724138/n\n",
      "Recall:0.6666666666666666/n\n",
      "F1:0.6428571428571429/n\n"
     ]
    }
   ],
   "source": [
    "### Support Vector Machine \n",
    "JVMNotFoundException: \n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "\n",
    "print(np.shape(X_train))\n",
    "\n",
    "\n",
    "# ## use gridsearch \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid ={\"kernel\":['linear', 'poly', 'rbf', 'sigmoid', ],\n",
    "#         'C': [0.1, .5, 1, 2, 3, 4, 5, 6, 7 ,8, 9, 10, 100],\n",
    "#         'gamma': ['scale', 'auto']\n",
    "#       }\n",
    "# model=svm.SVC()\n",
    "# clf_cv=GridSearchCV(clf,grid,cv=10) #GridSearchCV\n",
    "\n",
    "# model.fit(X_train,y_train)\n",
    "# print(\"tuned hyperparameters :\",clf_cv.best_params_)\n",
    "\n",
    "# ## gridsearch output returns tuned hyperparameters : {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, so we use that \n",
    "\n",
    "\n",
    "## use KFold CV as well \n",
    "from sklearn.model_selection import KFold\n",
    "scores=[]\n",
    "kFold=KFold(n_splits=8,shuffle=False)\n",
    "\n",
    "## use best gridsearch parameter\n",
    "model=svm.SVC(C=.1, gamma='scale',kernel='linear')\n",
    "for train_index,test_index in kFold.split(X_scaled):\n",
    "    # print(\"Train Index: \", train_index, \"\\n\")\n",
    "    # print(\"Test Index: \", test_index)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X_scaled[train_index], X_scaled[test_index], y[train_index], y[test_index]\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(model, X_scaled, y, cv=8))\n",
    "\n",
    "\n",
    "\n",
    "## finally, run the algorithm one last time on a random split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "scores.append(model.score(X_test,y_test))\n",
    "\n",
    "\n",
    "preds=model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "    \n",
    "C=confusion_matrix(y_test, preds)\n",
    "\n",
    "print(C)\n",
    "\n",
    "\n",
    "tp=C[0,0]\n",
    "tn=C[1,1] \n",
    "\n",
    "fp=C[0,1]\n",
    "fn=C[1,0]\n",
    "\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "\n",
    "\n",
    "\n",
    "f1=2*tp/((2*tp)+fp+fn)\n",
    "\n",
    "print('Precision:'+str(precision)+'/n')\n",
    "print('Recall:'+str(recall)+'/n')\n",
    "print('F1:'+str(f1)+'/n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89344830-0168-42bb-888d-970818b32d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 17)\n",
      "0.6072635135135135\n",
      "[0.7027027  0.59459459 0.54054054 0.62162162 0.56756757 0.58333333\n",
      " 0.66666667 0.75      ]\n",
      "[[17  8]\n",
      " [11 23]]\n",
      "Precision:0.68/n\n",
      "Recall:0.6071428571428571/n\n",
      "F1:0.6415094339622641/n\n"
     ]
    }
   ],
   "source": [
    "### Decision Tree\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "\n",
    "print(np.shape(X_train))\n",
    "\n",
    "\n",
    "# # ## use gridsearch \n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid ={\"criterion\":['gini', 'entropy', 'log_loss' ],\n",
    "#         'max_features': np.arange(1,15),\n",
    "#         'max_depth': np.arange(1,15),\n",
    "#         'min_samples_split':np.arange(1,10)\n",
    "#         }\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# model=DecisionTreeClassifier()\n",
    "# clf_cv=GridSearchCV(model,grid,cv=10) #GridSearchCV\n",
    "\n",
    "# clf_cv.fit(X_train,y_train)\n",
    "# print(\"tuned hyperparameters :\",clf_cv.best_params_)\n",
    "\n",
    "## gridsearch output returns tuned hyperparameters : {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 10, 'min_samples_split': 2}, so we use that \n",
    "\n",
    "\n",
    "## use KFold CV as well \n",
    "from sklearn.model_selection import KFold\n",
    "scores=[]\n",
    "kFold=KFold(n_splits=8,shuffle=False)\n",
    "\n",
    "## use best gridsearch parameter\n",
    "model=DecisionTreeClassifier(criterion='log_loss',max_depth=5,max_features=10,min_samples_split=2)\n",
    "for train_index,test_index in kFold.split(X_scaled):\n",
    "    # print(\"Train Index: \", train_index, \"\\n\")\n",
    "    # print(\"Test Index: \", test_index)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X_scaled[train_index], X_scaled[test_index], y[train_index], y[test_index]\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(model, X_scaled, y, cv=8))\n",
    "\n",
    "\n",
    "\n",
    "## finally, run the algorithm one last time on a random split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "scores.append(model.score(X_test,y_test))\n",
    "\n",
    "\n",
    "preds=model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "    \n",
    "C=confusion_matrix(y_test, preds)\n",
    "\n",
    "print(C)\n",
    "\n",
    "\n",
    "tp=C[0,0]\n",
    "tn=C[1,1] \n",
    "\n",
    "fp=C[0,1]\n",
    "fn=C[1,0]\n",
    "\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "\n",
    "\n",
    "\n",
    "f1=2*tp/((2*tp)+fp+fn)\n",
    "\n",
    "print('Precision:'+str(precision)+'/n')\n",
    "print('Recall:'+str(recall)+'/n')\n",
    "print('F1:'+str(f1)+'/n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "780a6fa0-4a9c-4148-b3d4-cd99c3d998d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Neural network \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_scaled, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "### Neural network \n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "powers_of_two=[2,4,16,32,64]\n",
    "\n",
    "# Input layer with 2 hidden layers\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=10))\n",
    "\n",
    "model.add(Dense(units=power_of_two[2], activation='relu'))\n",
    "\n",
    "model.add(Dense(units=power_of_two[3], activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=.01),\n",
    "              loss='categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=1,\n",
    "    epochs=1000,\n",
    ")\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f3eaf-c8e0-48e8-9e17-fed9a0b70cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
